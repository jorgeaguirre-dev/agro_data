# Agro Data Pipeline

Pipeline de datos para procesamiento de informaciÃ³n agrÃ­cola en AWS.
>Objetivo: Ingestar un CSV "rinde_lotes.csv" y "clima_diario.csv" a un bucket S3/curated en Parquet particionado por campaÃ±a y lote. Validar: rangos de rinde, % nulos, consistencia de fechas; exponer una vista para BI (Athena).

## ðŸ—ï¸ Arquitectura

S3 Landing â†’ Step Functions â†’ Glue Jobs â†’ S3 Curated â†’ Crawlers â†’ Glue Catalog â†’ Athena
â†“
Data Quality (Great Expectations)
â†“
Resultados en S3 (dq_results/)

- **Ingesta**: CSV â†’ S3 Landing
- **Procesamiento**: AWS Glue (PySpark)
- **OrquestaciÃ³n**: AWS Step Functions
- **CatÃ¡logo**: AWS Glue Data Catalog
- **Data Quality**: Great Expectations
- **Consumo**: Amazon Athena

## ðŸ“ Estructura del Proyecto
```
agro_data/
â”œâ”€â”€ .github/workflows/ # CI/CD
â”œâ”€â”€ infra/ # Terraform
â”œâ”€â”€ src/ # CÃ³digo fuente
â”‚ â”œâ”€â”€ ingestion/ # Jobs de Glue
â”‚ â””â”€â”€ dq/ # Data Quality
â””â”€â”€ orchestration/ # Step Functions
```

## Componentes implementados

### âœ… Infraestructura (Terraform)
- Buckets S3: landing, curated, scripts
- Roles IAM con mÃ­nimo privilegio
- Jobs de Glue (PySpark)
- Crawlers para actualizar catÃ¡logo
- Step Functions para orquestaciÃ³n
- Base de datos en Glue Catalog

### âœ… Procesamiento (PySpark)
- Lectura de CSVs desde landing
- Validaciones de rango (rinde 0-20000, temp -20-50, precip 0-500)
- Control de nulos en columnas crÃ­ticas
- Escritura en formato Parquet particionado (campaÃ±a/lote)

### âœ… Data Quality (Great Expectations)
- Suite de validaciones para rinde_lotes
- Suite de validaciones para clima_diario
- Resultados almacenados en S3 (dq_results/)
- Reintentos automÃ¡ticos para sincronizaciÃ³n de catÃ¡logo

### âœ… OrquestaciÃ³n (Step Functions)
- Flujo secuencial: Rinde â†’ Clima â†’ Crawlers â†’ DQ Rinde â†’ DQ Clima
- Manejo de errores y reintentos
- PrÃ³xima mejora: EjecuciÃ³n programada (CloudWatch Events)

### âœ… Seguridad (IAM)
Se proveen los archivos de configuraciÃ³n de perfiles apropiados para los perfiles: (carpeta iam)
- Perfil administrador (terraform apply)
- Perfil ingestiÃ³n (solo escritura a landing)
- Perfil BI (solo lectura a curated y Athena)

### âœ… Monitoreo
Es posible monitorear mediante:
- Logs en CloudWatch
- MÃ©tricas de ejecuciÃ³n
- Resultados DQ visibles en S3

## Costos estimados (mensuales)
- S3 (50GB) almacenamiento y operaciones: $1.15
- Glue (2 jobs x 10min/dÃ­a) 2DPU: $8.40
- Step Functions (30 ejecuciones): $1.00
- Athena (10GB escaneados): $0.50
- **Total: ~usd 11.40/mes**

## ðŸ“‹ Prerrequisitos

- AWS CLI configurado
- Terraform >= 1.0
- Python 3.9+

## ðŸš€ Comandos para Deploy y Operaciones

```bash
# 1. Clonar repositorio
git clone agro_data
cd agro_data

# Desplegar infraestructura
cd infra && terraform apply

# Subir scripts necesarios para el funcionamiento
./scripts/upload_scripts.sh

# Subir datos de ejemplo de la carpeta /data
./scripts/upload_data.sh
```
![Data Subida](img/data_subida.png)

```bash
# Ejecutar pipeline (luego de que la infra estÃ¡ lista)
./scripts/run_step_function.sh

# Ver resultados DQ
aws s3 ls s3://agro-data-pipeline-dev-curated/dq_results/ --recursive
```

![Curated Bucket](img/curated_bucket.png)

![Parquet Data](img/parquet_data.png)

```bash
# Consultar en Athena (en su consola de queries)
SELECT * FROM 'agro-data-pipeline_dev_db'.'rinde_lotes' LIMIT 10;

# Realizar una consulta SQL desde la cli de aws
aws athena start-query-execution \
  --query-string "SELECT * FROM 'agro-data-pipeline_dev_db'.'rinde_lotes' LIMIT 10;" \
  --result-configuration "OutputLocation=s3://agro-data-pipeline-dev-curated/athena-results/" \
  --output text \
  --query 'QueryExecutionId'

# Ver archivos Parquet generados
aws s3 ls s3://agro-data-pipeline-dev-curated/rinde_lotes/ --recursive
aws s3 ls s3://agro-data-pipeline-dev-curated/clima_diario/ --recursive
```

## DAG
![Pipeline DAG](./img/DAG.png)

![Jobs de Glue](img/jobs_Glue.png)

## Idempotencia en los jobs de Glue:
Los jobs son idempotentes porque:
- Sobrescriben particiones con mode("overwrite")
- Procesan archivo por archivo con timestamp en nombre
- Si el mismo archivo se procesa dos veces â†’ mismo resultado

## âœ… Data Quality

Great Expectations valida:
- No nulos en columnas crÃ­ticas
- Rangos de rinde (0-20000)
- Rangos climÃ¡ticos (temp -20/50, precip 0-500)
- Formato de fechas YYYY-MM-DD


## ðŸ“Š BI y VisualizaciÃ³n

- **Athena**: Consultas SQL directas

![Consulta Athena](img/consultas_athena.png)